# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Deleting a daemonset may need some trick. See
# https://github.com/kubernetes/kubernetes/issues/33245#issuecomment-261250489
apiVersion: extensions/v1beta1
kind: DaemonSet
metadata:
  name: hdfs-datanode
spec:
  template:
    metadata:
      labels:
        name: hdfs-datanode
    spec:
      hostNetwork: true
      hostPID: true
      containers:
        - name: datanode
          image: uhopper/hadoop-datanode:2.7.2
          env:
            # The below uses two loops to make sure the last item does not have comma. It uses index 0
            # for the last item since that is the only special index that helm template gives us.
            - name: HDFS_CONF_dfs_datanode_data_dir
              value: |-
              {{- range $index, $path := .Values.dataNodeHostPath }}
                {{- if ne $index 0 }}
                  /hadoop/dfs/data/{{ $index }},
                {{- end }}
              {{- end }}
              {{- range $index, $path := .Values.dataNodeHostPath }}
                {{- if eq $index 0 }}
                  /hadoop/dfs/data/{{ $index }}
                {{- end }}
              {{- end }}
            # This works only with /etc/resolv.conf mounted from the config map.
            # K8s version 1.6 will fix this, per https://github.com/kubernetes/kubernetes/pull/29378.
            - name: CORE_CONF_fs_defaultFS
              value: hdfs://hdfs-namenode-0.hdfs-namenode.default.svc.{{ .Values.clusterDomain }}:8020
          livenessProbe:
            initialDelaySeconds: 30
            httpGet:
              host: 127.0.0.1
              path: /
              port: 50075
          securityContext:
            privileged: true
          volumeMounts:
            {{- range $index, $path := .Values.dataNodeHostPath }}
            - name: hdfs-data-{{ $index }}
              mountPath: /hadoop/dfs/data/{{ $index }}
            {{- end }}
            # Use subPath below to mount only a single file.
            # See https://github.com/dshulyak/kubernetes.github.io/commit/d58ba7b075bb4848349a2c920caaa08ff3773d70
            - name: resolv-conf-volume
              mountPath: /etc/resolv.conf
              subPath: resolv.conf
      restartPolicy: Always
      volumes:
        {{- range $index, $path := .Values.dataNodeHostPath }}
        - name: hdfs-data-{{ $index }}
          hostPath:
            path: {{ $path }}
        {{- end }}
        - configMap:
            name: hdfs-resolv-conf
            items:
            - key: resolv.conf
              path: resolv.conf
          name: resolv-conf-volume
