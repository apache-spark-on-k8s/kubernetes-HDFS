# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# A headless service to create DNS records.
apiVersion: v1
kind: Service
metadata:
  name: hdfs-namenode
  labels:
    app: hdfs-namenode
spec:
  ports:
  - port: 8020
    name: fs
  - port: 50070
    name: http
  clusterIP: None
  selector:
    app: hdfs-namenode
---
apiVersion: apps/v1beta1
kind: StatefulSet
metadata:
  name: hdfs-namenode
spec:
  serviceName: "hdfs-namenode"
  {{- if .Values.namenodeHAEnabled }}
  # Create a size-2 set. The namenode DNS names will be
  # hdfs-namenode-0.hdfs-namenode.default.svc.cluster.local
  # and hdfs-namenode-1.hdfs-namenode.default.svc.cluster.local
  replicas: 2
  {{ else }}
  # Create a size-1 set. The namenode DNS name will be
  # hdfs-namenode-0.hdfs-namenode.default.svc.cluster.local
  replicas: 1
  {{ end }}
  template:
    metadata:
      labels:
        app: hdfs-namenode
    spec:
      # Use hostNetwork so datanodes connect to namenode without going through an overlay network
      # like weave. Otherwise, namenode fails to see physical IP address of datanodes.
      hostNetwork: true
      hostPID: true
      dnsPolicy: ClusterFirstWithHostNet
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchExpressions:
                  - key: "app"
                    operator: In
                    values:
                    - hfds-namenode
              topologyKey: "kubernetes.io/hostname"
      containers:
        - name: hdfs-namenode
          image: uhopper/hadoop-namenode:2.7.2
          env:
            # The following env vars are listed according to low-to-high precedence order.
            # i.e. Whoever comes last will override the earlier value of the same variable.
            {{- if .Values.namenodeHAEnabled }}
            - name: CORE_CONF_fs_defaultFS
              value: hdfs://hdfs-k8s
            # FIXME. Use all three zk-svc members.
            - name: CORE_CONF_ha_zookeeper_quorum
              value: zk-0.zk-svc.default.svc.cluster.local:2181
            - name: HDFS_CONF_dfs_nameservices
              value: hdfs-k8s
            - name: HDFS_CONF_dfs_ha_namenodes_hdfs___k8s
              value: nn0,nn1
            - name: HDFS_CONF_dfs_namenode_rpc___address_hdfs___k8s_nn0
              value: hdfs-namenode-0.hdfs-namenode.default.svc.cluster.local:8020
            - name: HDFS_CONF_dfs_namenode_rpc___address_hdfs___k8s_nn1
              value: hdfs-namenode-1.hdfs-namenode.default.svc.cluster.local:8020
            - name: HDFS_CONF_dfs_namenode_http___address_hdfs___k8s_nn0
              value: hdfs-namenode-0.hdfs-namenode.default.svc.cluster.local:50070
            - name: HDFS_CONF_dfs_namenode_http___address_hdfs___k8s_nn1
              value: hdfs-namenode-1.hdfs-namenode.default.svc.cluster.local:50070
            # FIXME. Use all three hdfs-journalnode members.
            - name: HDFS_CONF_dfs_namenode_shared_edits_dir
              value: qjournal://hdfs-journalnode-0.hdfs-journalnode.default.svc.cluster.local:8485/hdfs-k8s
            - name: HDFS_CONF_dfs_ha_automatic___failover_enabled
              value: "true"
            - name: HDFS_CONF_dfs_ha_fencing_methods
              value: "shell(/bin/true)"
            - name: HDFS_CONF_dfs_client_failover_proxy_provider_hdfs___k8s
              value: org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider
            {{- else }}
            - name: CLUSTER_NAME
              value: hdfs-k8s
            {{- end }}
            {{- if .Values.kerberosEnabled }}
            - name: CORE_CONF_hadoop_security_authentication
              value: kerberos
            - name: CORE_CONF_hadoop_security_authorization
              value: "true"
            - name: CORE_CONF_hadoop_rpc_protection
              value: privacy
            - name: HDFS_CONF_dfs_block_access_token_enable
              value: "true"
            - name: HDFS_CONF_dfs_encrypt_data_transfer
              value: "true"
            - name: HDFS_CONF_dfs_namenode_kerberos_principal
              value: hdfs/_HOST@{{ required "A valid kerberosRealm entry required!" .Values.kerberosRealm }}
            - name: HDFS_CONF_dfs_namenode_kerberos_https_principal
              value: http/_HOST@{{ required "A valid kerberosRealm entry required!" .Values.kerberosRealm }}
            - name: HDFS_CONF_dfs_web_authentication_kerberos_principal
              value: http/_HOST@{{ required "A valid kerberosRealm entry required!" .Values.kerberosRealm }}
            - name: HDFS_CONF_dfs_namenode_keytab_file
              value: /etc/security/hdfs.keytab
            {{- end }}
            {{- range $key, $value := .Values.customHadoopConfig }}
            - name: {{ $key | quote }}
              value: {{ $value | quote }}
            {{- end }}
            - name: MULTIHOMED_NETWORK
              value: "0"
          {{- if .Values.namenodeHAEnabled }}
          command: ['/bin/sh', '-c']
          args:
            - /entrypoint.sh /nn-start-script/run.sh
          {{- end }}
          ports:
          - containerPort: 8020
            name: fs
          - containerPort: 50070
            name: http
          volumeMounts:
            - name: hdfs-name
              mountPath: /hadoop/dfs/name
            {{- if .Values.namenodeHAEnabled }}
            - name: nn-start-script
              mountPath: /nn-start-script
              readOnly: true
            {{- end }}
            {{- if .Values.kerberosEnabled }}
            - name: kerberos-config
              mountPath: /etc/krb5.conf
              subPath: {{ .Values.kerberosConfigFileName }}
              readOnly: true
            - name: kerberos-keytab-copy
              mountPath: /etc/security/
              readOnly: true
            {{- end }}
      initContainers:
      {{- if .Values.namenodeHAEnabled }}
        - name: create-nn-start-script
          image: busybox:1.27.1
          command: ['sh', '-c']
          args:
            - (echo '#!/bin/bash' > /nn-start-script/run.sh)
          volumeMounts:
            - name: nn-start-script
              mountPath: /nn-start-script/
        - name: write-nn-format-in-start-script
          image: busybox:1.27.1
          command: ['sh', '-c']
          args:
            - if [ "$(echo $MY_POD | cut -c 1-15)" == "hdfs-namenode-0" ]; then (echo 'if [ ! -d /hadoop/dfs/name/current ]; then $HADOOP_PREFIX/bin/hdfs --config $HADOOP_CONF_DIR namenode -format -force -nonInteractive hdfs-k8s; $HADOOP_PREFIX/bin/hdfs --config $HADOOP_CONF_DIR zkfc -formatZK -force -nonInteractive; fi' >> /nn-start-script/run.sh); else (echo 'if [ ! -d /hadoop/dfs/name/current ]; then $HADOOP_PREFIX/bin/hdfs --config $HADOOP_CONF_DIR namenode -bootstrapStandby -force -nonInteractive; fi' >> /nn-start-script/run.sh); fi
          env:
            - name: MY_POD
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
          volumeMounts:
            - name: hdfs-name
              mountPath: /hadoop/dfs/name
            - name: nn-start-script
              mountPath: /nn-start-script/
        - name: wrap-up-nn-start-script
          image: busybox:1.27.1
          command: ['sh', '-c']
          args:
            - (echo '$HADOOP_PREFIX/sbin/hadoop-daemon.sh --config $HADOOP_CONF_DIR start zkfc' >> /nn-start-script/run.sh); (echo '$HADOOP_PREFIX/bin/hdfs --config $HADOOP_CONF_DIR namenode' >> /nn-start-script/run.sh); chmod +x /nn-start-script/run.sh
          volumeMounts:
            - name: nn-start-script
              mountPath: /nn-start-script/
      {{- end }}
      {{- if .Values.kerberosEnabled }}
        - name: copy-kerberos-keytab
          image: busybox:1.27.1
          command: ['sh', '-c']
          args:
            - cp /kerberos-keytabs/$MY_NODE_NAME.keytab /kerberos-keytab-copy/hdfs.keytab
          env:
            - name: MY_NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
          volumeMounts:
            - name: kerberos-keytabs
              mountPath: /kerberos-keytabs
            - name: kerberos-keytab-copy
              mountPath: /kerberos-keytab-copy
      {{- end }}
      {{- if not .Values.namenodeHAEnabled }}
      # Pin the pod to a node. You can label your node like below:
      #   $ kubectl label nodes YOUR-NODE hdfs-namenode-selector=hdfs-namenode-0
      # FIXME: Find a way to ping the two HA namenodes to two cluster nodes.
      nodeSelector:
        hdfs-namenode-selector: hdfs-namenode-0
      {{- end }}
      restartPolicy: Always
      volumes:
        # FIXME: Use PVs in case of HA.
        - name: hdfs-name
          hostPath:
            path: {{ .Values.nameNodeHostPath }}
        {{- if .Values.namenodeHAEnabled }}
        - name: nn-start-script
          emptyDir: {}
        {{- end }}
        {{- if .Values.kerberosEnabled }}
        - name: kerberos-config
          configMap:
            name: {{ .Values.kerberosConfigMap }}
        - name: kerberos-keytabs
          secret:
            secretName: {{ .Values.kerberosKeytabsSecret }}
        - name: kerberos-keytab-copy
          emptyDir: {}
        {{- end }}
