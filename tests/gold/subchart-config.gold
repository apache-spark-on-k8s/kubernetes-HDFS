


NAME:   my-hdfs-config
REVISION: 1
CHART: hdfs-0.1.0
USER-SUPPLIED VALUES:
condition:
  subchart:
    config: true
global:
  dataNodeHostPath:
  - /mnt/sda1/hdfs-data
  defaultAffinityEnabled: false
  fullnameOverride: my-hdfs
  zookeeperQuorumSize: 1
hdfs-namenode-k8s:
  hostNetworkEnabled: false
tags:
  ha: false
zookeeper:
  env:
    ZK_HEAP_SIZE: 100m
  replicaCount: 1
  resources:
    requests:
      memory: 100m

COMPUTED VALUES:
condition:
  subchart:
    config: true
global:
  dataNodeHostPath:
  - /mnt/sda1/hdfs-data
  defaultAffinityEnabled: false
  fullnameOverride: my-hdfs
  journalnodeQuorumSize: 3
  jsvcEnabled: true
  kerberosConfigFileName: krb5.conf
  kerberosEnabled: false
  kerberosRealm: MYCOMPANY.COM
  namenodeHAEnabled: true
  podSecurityContext:
    enabled: false
    fsGroup: 1000
    runAsUser: 0
  zookeeperQuorumSize: 1
hdfs-config-k8s:
  customHadoopConfig:
    coreSite: {}
    hdfsSite: {}
  global:
    dataNodeHostPath:
    - /mnt/sda1/hdfs-data
    defaultAffinityEnabled: false
    fullnameOverride: my-hdfs
    journalnodeQuorumSize: 3
    jsvcEnabled: true
    kerberosConfigFileName: krb5.conf
    kerberosEnabled: false
    kerberosRealm: MYCOMPANY.COM
    namenodeHAEnabled: true
    podSecurityContext:
      enabled: false
      fsGroup: 1000
      runAsUser: 0
    zookeeperQuorumSize: 1
hdfs-datanode-k8s:
  affinity: {}
  nodeSelector: {}
  tolerations: []
hdfs-journalnode-k8s:
  affinity: {}
  nodeSelector: {}
  persistence:
    accessMode: ReadWriteOnce
    size: 20Gi
  tolerations: []
hdfs-krb5-k8s:
  image:
    pullPolicy: IfNotPresent
    repository: gcavalcante8808/krb5-server
    tag: latest
  persistence:
    accessMode: ReadWriteOnce
    size: 20Gi
  service:
    port: 88
    type: ClusterIP
hdfs-namenode-k8s:
  affinity: {}
  customRunScript: |
    #!/bin/bash -x
    echo Write your own script content!
    echo This message will disappear in 10 seconds.
    sleep 10
  hostNetworkEnabled: false
  namenodeStartScript: format-and-run.sh
  nodeSelector: {}
  persistence:
    accessMode: ReadWriteOnce
    size: 100Gi
  tolerations: []
hdfs-simple-namenode-k8s:
  affinity: {}
  nameNodeHostPath: /hdfs-name
  nodeSelector: {}
  tolerations: []
tags:
  ha: false
  kerberos: false
  simple: false
zookeeper:
  env:
    ZK_HEAP_SIZE: 100m
  replicaCount: 1
  resources:
    requests:
      memory: 100m

HOOKS:
MANIFEST:

---
# Source: hdfs/charts/hdfs-config-k8s/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-hdfs-config
  labels:
    app: hdfs-client
    chart: hdfs-config-k8s-0.1.0
    release: my-hdfs-config
data:
  core-site.xml: |
    <?xml version="1.0"?>
    <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
    <configuration>
      <property>
        <name>fs.defaultFS</name>
        <value>hdfs://hdfs-k8s</value>
      </property>
      <property>
        <name>ha.zookeeper.quorum</name>
        <value>my-hdfs-zookeeper-0.my-hdfs-zookeeper-headless.default.svc.cluster.local:2181</value>
      </property>
    </configuration>
  hdfs-site.xml: |
    <?xml version="1.0"?>
    <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
    <configuration>
      <property>
        <name>dfs.nameservices</name>
        <value>hdfs-k8s</value>
      </property>
      <property>
        <name>dfs.ha.namenodes.hdfs-k8s</name>
        <value>nn0,nn1</value>
      </property>
      <property>
        <name>dfs.namenode.rpc-address.hdfs-k8s.nn0</name>
        <value>my-hdfs-namenode-0.my-hdfs-namenode.default.svc.cluster.local:8020</value>
      </property>
      <property>
        <name>dfs.namenode.rpc-address.hdfs-k8s.nn1</name>
        <value>my-hdfs-namenode-1.my-hdfs-namenode.default.svc.cluster.local:8020</value>
      </property>
      <property>
        <name>dfs.namenode.http-address.hdfs-k8s.nn0</name>
        <value>my-hdfs-namenode-0.my-hdfs-namenode.default.svc.cluster.local:50070</value>
      </property>
      <property>
        <name>dfs.namenode.http-address.hdfs-k8s.nn1</name>
        <value>my-hdfs-namenode-1.my-hdfs-namenode.default.svc.cluster.local:50070</value>
      </property>
      <property>
        <name>dfs.namenode.shared.edits.dir</name>
        <value>qjournal://my-hdfs-journalnode-1.my-hdfs-journalnode.default.svc.cluster.local:8485;my-hdfs-journalnode-2.my-hdfs-journalnode.default.svc.cluster.local:8485;my-hdfs-journalnode-0.my-hdfs-journalnode.default.svc.cluster.local:8485/hdfs-k8s</value>
      </property>
      <property>
        <name>dfs.ha.automatic-failover.enabled</name>
        <value>true</value>
      </property>
      <property>
        <name>dfs.ha.fencing.methods</name>
        <value>shell(/bin/true)</value>
      </property>
      <property>
        <name>dfs.journalnode.edits.dir</name>
        <value>/hadoop/dfs/journal</value>
      </property>
      <property>
        <name>dfs.client.failover.proxy.provider.hdfs-k8s</name>
        <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
      </property>
      <property>
        <name>dfs.namenode.name.dir</name>
        <value>file:///hadoop/dfs/name</value>
      </property>
      <property>
        <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
        <value>false</value>
      </property>
      <property>
        <name>dfs.datanode.data.dir</name>
        <value>/mnt/sda1/hdfs-data</value>
      </property>
    </configuration>
