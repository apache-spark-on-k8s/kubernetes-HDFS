


NAME:   my-hdfs-datanode
REVISION: 1
CHART: hdfs-0.1.0
USER-SUPPLIED VALUES:
condition:
  subchart:
    datanode: true
global:
  dataNodeHostPath:
  - /mnt/sda1/hdfs-data
  defaultAffinityEnabled: false
  fullnameOverride: my-hdfs
  zookeeperQuorumSize: 1
hdfs-namenode-k8s:
  hostNetworkEnabled: false
tags:
  ha: false
zookeeper:
  env:
    ZK_HEAP_SIZE: 100m
  replicaCount: 1
  resources:
    requests:
      memory: 100m

COMPUTED VALUES:
condition:
  subchart:
    datanode: true
global:
  dataNodeHostPath:
  - /mnt/sda1/hdfs-data
  defaultAffinityEnabled: false
  fullnameOverride: my-hdfs
  journalnodeQuorumSize: 3
  jsvcEnabled: true
  kerberosConfigFileName: krb5.conf
  kerberosEnabled: false
  kerberosRealm: MYCOMPANY.COM
  namenodeHAEnabled: true
  podSecurityContext:
    enabled: false
    fsGroup: 1000
    runAsUser: 0
  zookeeperQuorumSize: 1
hdfs-config-k8s:
  customHadoopConfig:
    coreSite: {}
    hdfsSite: {}
hdfs-datanode-k8s:
  affinity: {}
  global:
    dataNodeHostPath:
    - /mnt/sda1/hdfs-data
    defaultAffinityEnabled: false
    fullnameOverride: my-hdfs
    journalnodeQuorumSize: 3
    jsvcEnabled: true
    kerberosConfigFileName: krb5.conf
    kerberosEnabled: false
    kerberosRealm: MYCOMPANY.COM
    namenodeHAEnabled: true
    podSecurityContext:
      enabled: false
      fsGroup: 1000
      runAsUser: 0
    zookeeperQuorumSize: 1
  nodeSelector: {}
  tolerations: []
hdfs-journalnode-k8s:
  affinity: {}
  nodeSelector: {}
  persistence:
    accessMode: ReadWriteOnce
    size: 20Gi
  tolerations: []
hdfs-krb5-k8s:
  image:
    pullPolicy: IfNotPresent
    repository: gcavalcante8808/krb5-server
    tag: latest
  persistence:
    accessMode: ReadWriteOnce
    size: 20Gi
  service:
    port: 88
    type: ClusterIP
hdfs-namenode-k8s:
  affinity: {}
  customRunScript: |
    #!/bin/bash -x
    echo Write your own script content!
    echo This message will disappear in 10 seconds.
    sleep 10
  hostNetworkEnabled: false
  namenodeStartScript: format-and-run.sh
  nodeSelector: {}
  persistence:
    accessMode: ReadWriteOnce
    size: 100Gi
  tolerations: []
hdfs-simple-namenode-k8s:
  affinity: {}
  nameNodeHostPath: /hdfs-name
  nodeSelector: {}
  tolerations: []
tags:
  ha: false
  kerberos: false
  simple: false
zookeeper:
  env:
    ZK_HEAP_SIZE: 100m
  replicaCount: 1
  resources:
    requests:
      memory: 100m

HOOKS:
MANIFEST:

---
# Source: hdfs/charts/hdfs-datanode-k8s/templates/datanode-daemonset.yaml
# Provides datanode helper scripts.
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-hdfs-datanode-scripts
  labels:
    app: hdfs-datanode
    chart: hdfs-datanode-k8s-0.1.0
    release: my-hdfs-datanode
data:
  check-status.sh: |
    #!/usr/bin/env bash
    # Exit on error. Append "|| true" if you expect an error.
    set -o errexit
    # Exit on error inside any functions or subshells.
    set -o errtrace
    # Do not allow use of undefined vars. Use ${VAR:-} to use an undefined VAR
    set -o nounset
    # Catch an error in command pipes. e.g. mysqldump fails (but gzip succeeds)
    # in `mysqldump |gzip`
    set -o pipefail
    # Turn on traces, useful while debugging.
    set -o xtrace

    # Check if datanode registered with the namenode and got non-null cluster ID.
    _PORTS="50075 1006"
    _URL_PATH="jmx?qry=Hadoop:service=DataNode,name=DataNodeInfo"
    _CLUSTER_ID=""
    for _PORT in $_PORTS; do
      _CLUSTER_ID+=$(curl -s http://localhost:${_PORT}/$_URL_PATH |  \
          grep ClusterId) || true
    done
    echo $_CLUSTER_ID | grep -q -v null
---
# Source: hdfs/charts/hdfs-datanode-k8s/templates/datanode-daemonset.yaml
# Deleting a daemonset may need some trick. See
# https://github.com/kubernetes/kubernetes/issues/33245#issuecomment-261250489
apiVersion: extensions/v1beta1
kind: DaemonSet
metadata:
  name: my-hdfs-datanode
  labels:
    app: hdfs-datanode
    chart: hdfs-datanode-k8s-0.1.0
    release: my-hdfs-datanode
spec:
  template:
    metadata:
      labels:
        app: hdfs-datanode
        release: my-hdfs-datanode
    spec:
      hostNetwork: true
      hostPID: true
      dnsPolicy: ClusterFirstWithHostNet
      containers:
        - name: datanode
          image: uhopper/hadoop-datanode:2.7.2
          env:
            - name: HADOOP_CUSTOM_CONF_DIR
              value: /etc/hadoop-custom-conf
            - name: MULTIHOMED_NETWORK
              value: "0"
          livenessProbe:
            exec:
              command:
                - /dn-scripts/check-status.sh
            initialDelaySeconds: 60
            periodSeconds: 30
          readinessProbe:
            exec:
              command:
                - /dn-scripts/check-status.sh
            initialDelaySeconds: 60
            periodSeconds: 30
          securityContext:
            privileged: true
          volumeMounts:
            - name: dn-scripts
              mountPath: /dn-scripts
              readOnly: true
            - name: hdfs-config
              mountPath: /etc/hadoop-custom-conf
              readOnly: true
            - name: hdfs-data-0
              mountPath: /hadoop/dfs/data/0
      restartPolicy: Always
      volumes:
        - name: dn-scripts
          configMap:
            name: my-hdfs-datanode-scripts
            defaultMode: 0744
        - name: hdfs-data-0
          hostPath:
            path: /mnt/sda1/hdfs-data
        - name: hdfs-config
          configMap:
            name: my-hdfs-config
